"""News Agent - ë‰´ìŠ¤ ë¶„ì„ ë° ê°ì„± ë¶„ë¥˜

ë…¼ë¬¸ Section 3.1: Enhanced News Analysis
- ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜ì§‘ ë° ê°ì„± ë¶„ì„
- ê¸ì •/ë¶€ì •/ì¤‘ë¦½ ë¶„ë¥˜
- ì£¼ìš” ì´ë²¤íŠ¸ ì¶”ì¶œ
"""
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, List

from .base_agent import BaseAgent
from src.storage.models import Stock, NewsArticle, DisclosureData, BlogPost

logger = logging.getLogger("marketsense")


class NewsAgent(BaseAgent):
    """ë‰´ìŠ¤ ë¶„ì„ ì—ì´ì „íŠ¸"""

    SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ë² í…Œë‘ ê¸ˆìœµ ë‰´ìŠ¤ ë¶„ì„ê°€ì…ë‹ˆë‹¤.

ë‹¹ì‹ ì˜ ëª©í‘œëŠ” íŠ¹ì • ê¸°ì—…ì— ëŒ€í•œ ë‰´ìŠ¤ íë¦„ì„ íŒŒì•…í•˜ê³ , ì´ë¥¼ í•˜ë‚˜ì˜ ì¼ê´€ëœ 'íˆ¬ì ì„œì‚¬(Narrative)'ë¡œ í†µí•©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
í•µì‹¬ ì›ì¹™:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. **ì‹¤ì§ˆì  ì˜í–¥ì— ì§‘ì¤‘**
   ì£¼ê°€ì— ì‹¤ì§ˆì ì¸ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì¤‘ìš” ì´ë²¤íŠ¸ì— ì§‘ì¤‘í•˜ì‹­ì‹œì˜¤:
   - ì‹¤ì  ë°œí‘œ (ë§¤ì¶œ, ì˜ì—…ì´ìµ ì¦ê°)
   - ì‹ ì œí’ˆ ì¶œì‹œ / ì‹ ê·œ ìˆ˜ì£¼
   - M&A, ì „ëµì  ì œíœ´
   - ê·œì œ ì´ìŠˆ, ì†Œì†¡
   - ê²½ì˜ì§„ ë³€í™”
   - ë°°ë‹¹, ìì‚¬ì£¼ ë§¤ì…
   
2. **ì„œì‚¬ êµ¬ì¶•**
   ë‹¨ìˆœ ë‚˜ì—´ì´ ì•„ë‹Œ, ì‚¬ê±´ì˜ íë¦„ì´ ì´ì–´ì§€ë„ë¡ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
   "Aê°€ ë°œìƒí–ˆê³ , ì´ì— ë”°ë¼ Bê°€ ì˜ˆìƒë˜ë©°, Cì˜ ì˜í–¥ì´ ìš°ë ¤ëœë‹¤"
   
3. **ì‹œê°„ ë§¥ë½ ìœ ì§€**
   - ìµœê·¼ ë‰´ìŠ¤ì™€ ê³¼ê±° ë§¥ë½ì„ ì—°ê²°
   - ì§„í–‰ ì¤‘ì¸ ì´ìŠˆëŠ” ê³„ì† ì¶”ì 
   - í•´ê²°ëœ ì´ìŠˆëŠ” ê²°ê³¼ ë°˜ì˜
   
4. **ì •ë³´ì› êµ¬ë¶„**
   - ê³µì‹ ë‰´ìŠ¤: ì‹ ë¢°ë„ ë†’ìŒ, íŒ©íŠ¸ ì¤‘ì‹¬
   - ë¸”ë¡œê·¸/ì»¤ë®¤ë‹ˆí‹°: ì°¸ê³ ìš©, ì‹œì¥ ì‹¬ë¦¬ íŒŒì•…
   - ê³µì‹œ ì •ë³´: ê³µì‹ ë°œí‘œ, ìµœìš°ì„  ê³ ë ¤
   
5. **íˆ¬ìì ê´€ì **
   íˆ¬ììê°€ ë¹ ë¥´ê²Œ íŒŒì•…í•  ìˆ˜ ìˆëŠ” ê°„ê²°í•œ ë¶„ì„ì„ ì œê³µí•˜ì‹­ì‹œì˜¤.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ì¶œë ¥ í˜•ì‹ (JSON):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

{
  "sentiment": "positive|negative|neutral",
  "confidence": 0.0-1.0,
  "impact": "high|medium|low",
  "narrative": "íˆ¬ì ì„œì‚¬ (2-3ë¬¸ë‹¨, ì‹œê°„ íë¦„ì— ë”°ë¥¸ í•µì‹¬ ìŠ¤í† ë¦¬)",
  "key_events": [
    {
      "event": "ì´ë²¤íŠ¸ ì„¤ëª…",
      "date": "YYYY-MM-DD",
      "impact": "ê¸ì •ì |ë¶€ì •ì |ì¤‘ë¦½",
      "importance": "high|medium|low"
    }
  ],
  "summary": "í•œ ì¤„ ìš”ì•½ (íˆ¬ìì í—¤ë“œë¼ì¸)",
  "reasoning": "ë¶„ì„ ê·¼ê±° ë° íŒë‹¨ ë…¼ë¦¬"
}
"""

    def analyze(self, ticker: str, lookback_days: int = 7, use_rag: bool = True) -> Dict[str, Any]:
        """ì¢…ëª© ë‰´ìŠ¤ ë¶„ì„"""
        logger.info(f"[NewsAgent] {ticker} ë‰´ìŠ¤ ë¶„ì„ ì‹œì‘ (ìµœê·¼ {lookback_days}ì¼, RAG={use_rag})")

        with self.db.get_session() as session:
            # ì¢…ëª© ì •ë³´
            stock = session.query(Stock).filter_by(ticker=ticker).first()
            if not stock:
                return {"error": f"ì¢…ëª© {ticker}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}

            # ìµœê·¼ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
            cutoff = datetime.now() - timedelta(days=lookback_days)
            
            if use_rag:
                # ë°©ë²• 1: ì‹œê°„ ìœˆë„ìš° + RAG
                try:
                    from src.rag.vector_store import VectorStore
                    
                    # RAG ê²€ìƒ‰ (ê´€ë ¨ì„± ìš°ì„ , ë§ì´ ê°€ì ¸ì˜´)
                    vs = VectorStore()
                    
                    rag_results = vs.search_news(
                        query=f"{stock.name} ì£¼ê°€ ì‹¤ì  ì „ë§ ë¶„ì„",
                        ticker=ticker,
                        top_k=50  # ë§ì´ ê°€ì ¸ì˜¨ í›„ ì‹œê°„ í•„í„°ë§
                    )
                    
                    # RAG ê²°ê³¼ë¥¼ DB ê°ì²´ë¡œ ë§¤í•‘í•˜ê³  ì‹œê°„ í•„í„°ë§
                    if rag_results:
                        rag_ids = [r['id'].replace('news_', '') for r in rag_results if r['id'].startswith('news_')]
                        
                        news_list = (
                            session.query(NewsArticle)
                            .filter(
                                NewsArticle.id.in_([int(i) for i in rag_ids if i.isdigit()]),
                                NewsArticle.published_at >= cutoff  # ì‹œê°„ ìœˆë„ìš°
                            )
                            .order_by(NewsArticle.published_at.desc())
                            .limit(20)  # ìµœì¢… 20ê°œ
                            .all()
                        )
                        
                        logger.info(f"[NewsAgent] RAG ê²€ìƒ‰: {len(news_list)}ê°œ (ìµœê·¼ {lookback_days}ì¼)")
                    else:
                        news_list = []
                    
                    # RAG ê²°ê³¼ ì—†ìœ¼ë©´ fallback
                    if not news_list:
                        logger.warning(f"[NewsAgent] RAG ê²°ê³¼ ì—†ìŒ, SQL fallback")
                        use_rag = False
                
                except Exception as e:
                    logger.warning(f"[NewsAgent] RAG ì‹¤íŒ¨ ({e}), SQL fallback")
                    use_rag = False
            
            if not use_rag:
                # Fallback: ê¸°ì¡´ SQL ë°©ì‹ (ìµœì‹ ìˆœ)
                news_list = (
                    session.query(NewsArticle)
                    .filter(
                        NewsArticle.ticker == ticker,
                        NewsArticle.published_at >= cutoff,
                    )
                    .order_by(NewsArticle.published_at.desc())
                    .limit(20)
                    .all()
                )
                logger.info(f"[NewsAgent] SQL ê²€ìƒ‰: {len(news_list)}ê°œ")

            if not news_list:
                return {
                    "ticker": ticker,
                    "stock_name": stock.name,
                    "news_count": 0,
                    "sentiment": "neutral",
                    "message": "ìµœê·¼ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤",
                }

            # ë‰´ìŠ¤ ìš”ì•½
            news_texts = []
            for idx, news in enumerate(news_list[:10], 1):
                date_str = news.published_at.strftime("%Y-%m-%d") if news.published_at else "ë‚ ì§œ ë¯¸ìƒ"
                news_texts.append(f"{idx}. [{date_str}] {news.title}")
                if news.summary:
                    news_texts.append(f"   ìš”ì•½: {news.summary[:150]}...")

            # ê³µì‹œ ì •ë³´ ì¡°íšŒ (ìµœê·¼ 30ì¼)
            disclosure_cutoff = datetime.now() - timedelta(days=30)
            disclosure_list = (
                session.query(DisclosureData)
                .filter(
                    DisclosureData.stock_id == stock.id,
                    DisclosureData.rcept_dt >= disclosure_cutoff.date(),
                )
                .order_by(DisclosureData.rcept_dt.desc())
                .limit(10)
                .all()
            )
            
            disclosure_texts = []
            if disclosure_list:
                disclosure_texts.append("\nì£¼ìš” ê³µì‹œ ì •ë³´ (ìµœê·¼ 30ì¼):")
                for idx, disc in enumerate(disclosure_list, 1):
                    date_str = disc.rcept_dt.strftime("%Y-%m-%d")
                    disclosure_texts.append(
                        f"{idx}. [{date_str}] {disc.disclosure_type}: {disc.report_nm[:80]}"
                    )

            # ë¸”ë¡œê·¸ ê¸€ ì¡°íšŒ (ìµœê·¼ 7ì¼)
            blog_list = (
                session.query(BlogPost)
                .filter(
                    BlogPost.stock_id == stock.id,
                    BlogPost.post_date >= cutoff.date(),
                )
                .order_by(BlogPost.quality_score.desc(), BlogPost.post_date.desc())
                .limit(10)
                .all()
            )
            
            blog_texts = []
            if blog_list:
                blog_texts.append("\nğŸ’¬ ë¸”ë¡œê·¸ íˆ¬ì ì˜ê²¬ (ìµœê·¼ 7ì¼, ê°œì¸ ì˜ê²¬):")
                for idx, blog in enumerate(blog_list, 1):
                    date_str = blog.post_date.strftime("%Y-%m-%d")
                    blog_texts.append(
                        f"{idx}. [{date_str}] {blog.title[:60]} (by {blog.blogger_name})"
                    )
                    if blog.description:
                        blog_texts.append(f"   â†’ {blog.description[:100]}...")

            # ì´ì „ ë‰´ìŠ¤ ì„œì‚¬ (ìˆë‹¤ë©´)
            previous_narrative = ""
            if stock.raw_data and isinstance(stock.raw_data, dict):
                previous_narrative = stock.raw_data.get('news_narrative', '')
            
            # Geminië¡œ ë¶„ì„
            prompt = f"""{self.SYSTEM_PROMPT}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š ë¶„ì„ ëŒ€ìƒ: {stock.name} ({ticker})
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

[1] ê¸°ì¡´ê¹Œì§€ì˜ ë‰´ìŠ¤ ìš”ì•½ ë° ì„œì‚¬:
{previous_narrative if previous_narrative else "ì‹ ê·œ ë¶„ì„ - ì´ì „ ì„œì‚¬ ì—†ìŒ"}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
[2] ìµœê·¼ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ({len(news_list)}ê±´, {lookback_days}ì¼)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

{chr(10).join(news_texts)}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
[3] ê³µì‹ ê³µì‹œ ì •ë³´ (ìµœê·¼ 30ì¼)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

{chr(10).join(disclosure_texts) if disclosure_texts else "ê³µì‹œ ì—†ìŒ"}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
[4] ë¸”ë¡œê·¸/ì»¤ë®¤ë‹ˆí‹° ì˜ê²¬ (ì°¸ê³ ìš©)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âš ï¸ ì£¼ì˜: ë¸”ë¡œê·¸ëŠ” ê°œì¸ ì˜ê²¬ì´ë¯€ë¡œ íŒ©íŠ¸ í™•ì¸ í•„ìš”

{chr(10).join(blog_texts) if blog_texts else "ë¸”ë¡œê·¸ ì˜ê²¬ ì—†ìŒ"}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“‹ ë¶„ì„ ì§€ì¹¨:

1. **í•µì‹¬ ì´ë²¤íŠ¸ ì‹ë³„**
   - ì‹¤ì  ë°œí‘œ, M&A, ì‹ ì œí’ˆ ë“± ì£¼ê°€ ì˜í–¥ ì´ë²¤íŠ¸ì— ì§‘ì¤‘
   - ê³µì‹œ ì •ë³´ëŠ” ìµœìš°ì„ ìœ¼ë¡œ key_eventsì— í¬í•¨
   - ë‹¨ìˆœ ë£¨ë¨¸ë‚˜ ì†Œë¬¸ì€ ë‚®ì€ ì¤‘ìš”ë„ë¡œ ì²˜ë¦¬

2. **ì„œì‚¬ êµ¬ì¶• (ì¤‘ìš”!)**
   - ê¸°ì¡´ ì„œì‚¬ê°€ ìˆë‹¤ë©´, ìƒˆë¡œìš´ ë‰´ìŠ¤ë¥¼ í†µí•©í•˜ì—¬ ì—…ë°ì´íŠ¸
   - ë‹¨ìˆœ ë‚˜ì—´ì´ ì•„ë‹Œ, ì‹œê°„ íë¦„ì— ë”°ë¥¸ ìŠ¤í† ë¦¬ ì‘ì„±
   - "Aê°€ ë°œìƒ â†’ Bë¡œ ì´ì–´ì§ â†’ Cê°€ ì˜ˆìƒë¨" í˜•ì‹
   - ì§„í–‰ ì¤‘ì¸ ì´ìŠˆëŠ” ê³„ì† ì¶”ì  (ì˜ˆ: ì†Œì†¡, í”„ë¡œì íŠ¸)

3. **ì •ë³´ì› ì‹ ë¢°ë„**
   - ê³µì‹œ > ë‰´ìŠ¤ > ë¸”ë¡œê·¸ ìˆœì„œ
   - ë¸”ë¡œê·¸ëŠ” ì‹œì¥ ì‹¬ë¦¬ íŒŒì•…ìš©, ë‚®ì€ ê°€ì¤‘ì¹˜
   - ë¸”ë¡œê·¸ë§Œìœ¼ë¡œ sentiment ê²°ì • ê¸ˆì§€

4. **íˆ¬ìì ê´€ì **
   - ê°„ê²°í•˜ê³  ëª…í™•í•œ narrative ì‘ì„±
   - íˆ¬ììê°€ ë¹ ë¥´ê²Œ íŒŒì•…í•  ìˆ˜ ìˆëŠ” í—¤ë“œë¼ì¸ ìš”ì•½
   - ëª¨í˜¸í•œ í‘œí˜„ ì§€ì–‘, êµ¬ì²´ì ì¸ íŒ©íŠ¸ ì¤‘ì‹¬

ìœ„ ì§€ì¹¨ì— ë”°ë¼ JSON í˜•ì‹ìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•˜ì„¸ìš”.
"""

            try:
                response_text = self.generate(prompt)
                # JSON íŒŒì‹± ì‹œë„
                import json
                # ```json ``` ì œê±°
                if "```json" in response_text:
                    response_text = response_text.split("```json")[1].split("```")[0]
                elif "```" in response_text:
                    response_text = response_text.split("```")[1].split("```")[0]

                result = json.loads(response_text.strip())
                result["ticker"] = ticker
                result["stock_name"] = stock.name
                result["news_count"] = len(news_list)
                result["analyzed_at"] = datetime.now().isoformat()

                # íˆ¬ì ì„œì‚¬ë¥¼ DBì— ì €ì¥ (ë‹¤ìŒ ë¶„ì„ ì‹œ í™œìš©)
                if "narrative" in result:
                    if not stock.raw_data:
                        stock.raw_data = {}
                    stock.raw_data['news_narrative'] = result['narrative']
                    stock.raw_data['news_updated_at'] = datetime.now().isoformat()
                    session.commit()
                    logger.debug(f"[NewsAgent] {ticker} íˆ¬ì ì„œì‚¬ DB ì €ì¥")

                logger.info(
                    f"[NewsAgent] {ticker} ë¶„ì„ ì™„ë£Œ: {result.get('sentiment')} "
                    f"(ì‹ ë¢°ë„ {result.get('confidence', 0):.2f})"
                )

                return result

            except Exception as e:
                logger.error(f"[NewsAgent] {ticker} ë¶„ì„ ì‹¤íŒ¨: {e}")
                return {
                    "ticker": ticker,
                    "stock_name": stock.name,
                    "news_count": len(news_list),
                    "error": str(e),
                }
